---
layout: post
title: Week 4
---

## Community Detection 

A notable feature of real-world networks is that they are irregular. In other words, some nodes in a real-world network have a high degree of edges, while most nodes have few edges. The distribution of edges is skewed to the left with a long tail and has been described as having a power-law distribution or lognormal distribution. 

This irregularity can be leveraged to group different areas of the graph together and, ultimately, simplify large graphs by identifying substructure. Take, for example, a large network of neurons. While examining the network as a whole might not provide many insights, identifying a group of densely connected neurons might help us identify that they share a common function. In a large social network, like Facebook or Reddit, grouping members based on their shared acquaintances, geographical location, or shared memberships might help us identify friend groups, school or sporting groups, and hobby groups.

This is known formally as community detection in network analysis. Communities, in this context, are groups of nodes that more densely interconnected, than they are to nodes outside the group. (Communities are interchangeably called 'clusters' or 'modules.')

Detecting communities is a conceptually and practically challenging problems. Conceptually, there is inherent ambiguity in the definition of community, because they can vary based on perspectives. Further, the node can belong to multiple communities. In our earlier example of communities in Facebook or Reddit, one person might belong to both the subreddits r/Crochet and r/Fountain, or an individual could have attended two different high schools. There is no universally accepted quantitative definition of community. 

Practically, once we have organized nodes into communities, we're left with the problem of evaluating the validity of our solution. When we're working with networks with a cardinality of 1 mil+ nodes and a lack of ground truth, there isn't a scalable solution for checking if every node has been assigned to the right community. Another practical consideration is the computational complexity engendered by increasingly large graphs. Algorithms designed to detect communities need to be able to iterate through graphs of nodes n and edges m in a reasonable amount of time. 

There are *many* algorithms, collectively referred to as 'clustering' algorithms, that iterate over a network and identify communities based on some mathematical definition of "community." These algorithms optimize for different aspects of a community and therefore, produce different clustering. The algorithm that is most widely-used currently is the Leiden Algorithm. 

## Reflections

This week, I am working on clustering the Stack Overflow network from the Stanford Network Analysis Project. For this assignment, I will not be including the temporal attributes, so the both the attributes and multiple edges between two users will be discarded. 

I have been working with some new packages for network analysis in Python: igraph, NetworkX, and NetworKit. One part of the assignment was taking an edge list and removing any self-loops or parallel edges. In the process of writing a script to do that, I realized I was trying to reinvent the wheel, and it would be more effective to use an existing graph package with the same functionality! I ended up using NetworkX to quickly clean my edge list.

The intent of this assignment is to familiarize myself with a widely-used clustering algorithm, the Leiden algorithm, by working with their Python package, as well as learning the impact of resolution on the granularity of clusters.  

## Learning Objectives

- Cloning and using the CM++ Pipeline
- Clustering Validity
- Cluster Connectivity



